{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tScJTexnyHku",
        "outputId": "48361168-7ed3-4b54-ed9f-04efa82d2333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjSRFELVbNk"
      },
      "source": [
        "# MMAction2 Tutorial\n",
        "\n",
        "Welcome to MMAction2! This is the official colab tutorial for using MMAction2. In this tutorial, you will learn\n",
        "- Perform inference with a MMAction2 recognizer.\n",
        "- Train a new recognizer with a new dataset.\n",
        "\n",
        "\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LqHGkGEVqpm"
      },
      "source": [
        "## Install MMAction2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf8PpPXtVvmg",
        "outputId": "705165f3-01aa-4aea-d152-df3aa1047bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Check nvcc version\n",
        "# !nvcc -V\n",
        "# # Check GCC version\n",
        "# !gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPwKGzqydnb2",
        "outputId": "eecc0a56-e454-4239-a519-508427a31c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.1%2Bcu118-cp310-cp310-linux_x86_64.whl (819.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.1+cu118\n"
          ]
        }
      ],
      "source": [
        "# # install dependencies: (if your colab has CUDA 11.8)\n",
        "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PAJ4ArzV5Ry",
        "outputId": "c37f774f-27c8-4e10-c143-1ae42604c708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openmim in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim) (0.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.28.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.5.2)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (3.20.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.65.2)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (0.0.35)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.25.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (2.17.0)\n",
            "Requirement already satisfied: setuptools~=60.2.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (60.2.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.2)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.15.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.2.0/index.html\n",
            "Requirement already satisfied: mmengine in /usr/local/lib/python3.10/dist-packages (0.10.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.25.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmengine) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (7.0.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.2.0/index.html\n",
            "Collecting mmcv>=2.0.0\n",
            "  Using cached mmcv-2.1.0.tar.gz (471 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.10.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (24.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.40.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (2.4.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (4.8.0.76)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (7.0.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.16.0)\n",
            "Building wheels for collected packages: mmcv\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for mmcv\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for mmcv\n",
            "Failed to build mmcv\n",
            "\u001b[31mERROR: Could not build wheels for mmcv, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22864, done.\u001b[K\n",
            "remote: Total 22864 (delta 0), reused 0 (delta 0), pack-reused 22864\u001b[K\n",
            "Receiving objects: 100% (22864/22864), 69.62 MiB | 32.94 MiB/s, done.\n",
            "Resolving deltas: 100% (16120/16120), done.\n",
            "/content/mmaction2\n",
            "Obtaining file:///content/mmaction2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decord>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (0.6.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (2.2.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.2.0) (1.3.0)\n",
            "Installing collected packages: mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "Successfully installed mmaction2-1.2.0\n",
            "Collecting av>=9.0 (from -r requirements/optional.txt (line 1))\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 2)) (0.18.3)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 4)) (0.10.1)\n",
            "Collecting lmdb (from -r requirements/optional.txt (line 5))\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 6)) (1.0.3)\n",
            "Collecting openai-clip (from -r requirements/optional.txt (line 7))\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 8)) (24.0)\n",
            "Collecting pims (from -r requirements/optional.txt (line 9))\n",
            "  Downloading PIMS-0.6.1.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyTurboJPEG (from -r requirements/optional.txt (line 10))\n",
            "  Downloading PyTurboJPEG-1.7.3.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 12)) (2.15.2)\n",
            "Collecting wandb (from -r requirements/optional.txt (line 13))\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (2.31.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (2.0.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (4.10.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.0.8)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (4.65.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (2.28.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (0.1.10)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (0.4.9)\n",
            "Collecting ftfy (from openai-clip->-r requirements/optional.txt (line 7))\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip->-r requirements/optional.txt (line 7)) (2023.12.25)\n",
            "Collecting slicerator>=0.9.8 (from pims->-r requirements/optional.txt (line 9))\n",
            "  Downloading slicerator-1.1.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r requirements/optional.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (60.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (3.0.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.5/263.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (6.0.1)\n",
            "Collecting setproctitle (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (1.4.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r requirements/optional.txt (line 11)) (2.21)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements/optional.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->-r requirements/optional.txt (line 4)) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (2024.2.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug->-r requirements/optional.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug->-r requirements/optional.txt (line 3)) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug->-r requirements/optional.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements/optional.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements/optional.txt (line 12)) (2.1.5)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip->-r requirements/optional.txt (line 7)) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements/optional.txt (line 12)) (3.2.2)\n",
            "Building wheels for collected packages: openai-clip, pims, PyTurboJPEG\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368645 sha256=54e47691ebc5e5d22395ba504d779e6e827a29cb873b8fd8e377886b3f07b0c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n",
            "  Building wheel for pims (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pims: filename=PIMS-0.6.1-py3-none-any.whl size=82628 sha256=0bc98979219eebfa39fc16068384390146c4e4cf6a0f34e0380efc88e2ee837e\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/bf/3e/bfa77232d942f8244145f9c713b6b38f6ef04b6fb5c021c114\n",
            "  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.7.3-py3-none-any.whl size=12463 sha256=729a53021a770dadc74c8755f708596a490c2c0c99c60feabb21e761f277ecff\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/bb/3d/d1032d5ec98ae80c4f92f41a07773d4f9641c64a10fd8c31b4\n",
            "Successfully built openai-clip pims PyTurboJPEG\n",
            "Installing collected packages: slicerator, lmdb, smmap, setproctitle, sentry-sdk, PyTurboJPEG, ftfy, docker-pycreds, av, pims, openai-clip, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 PyTurboJPEG-1.7.3 av-11.0.0 docker-pycreds-0.4.0 ftfy-6.1.3 gitdb-4.0.11 lmdb-1.4.1 openai-clip-1.0.1 pims-0.6.1 sentry-sdk-1.42.0 setproctitle-1.3.3 slicerator-1.1.0 smmap-5.0.1 wandb-0.16.4\n"
          ]
        }
      ],
      "source": [
        "# # install MMEngine, MMCV and MMDetection using MIM\n",
        "# %pip install -U openmim\n",
        "# !mim install mmengine\n",
        "# !mim install \"mmcv>=2.0.0\"\n",
        "\n",
        "# # Install mmaction2\n",
        "# !rm -rf mmaction2\n",
        "# !git clone https://github.com/open-mmlab/mmaction2.git -b main\n",
        "# %cd mmaction2\n",
        "\n",
        "# !pip install -e .\n",
        "\n",
        "# # Install some optional requirements\n",
        "# !pip install -r requirements/optional.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "No_zZAFpWC-a",
        "outputId": "579462b0-2cf1-41ce-e01f-59e8838ff297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.1 True\n",
            "1.2.0\n",
            "12.3\n",
            "MSVC 193933521\n",
            "OrderedDict([('sys.platform', 'win32'), ('Python', '3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]'), ('CUDA available', True), ('MUSA available', False), ('numpy_random_seed', 2147483648), ('GPU 0', 'NVIDIA GeForce RTX 2060'), ('CUDA_HOME', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.3'), ('NVCC', 'Cuda compilation tools, release 12.3, V12.3.107'), ('MSVC', 'n/a, reason: fileno'), ('PyTorch', '2.2.1'), ('PyTorch compiling details', 'PyTorch built with:\\n  - C++ Version: 201703\\n  - MSVC 192930151\\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)\\n  - OpenMP 2019\\n  - LAPACK is enabled (usually provided by MKL)\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 12.1\\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n  - CuDNN 8.8.1  (built against CUDA 12.0)\\n  - Magma 2.5.4\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \\n'), ('TorchVision', '0.17.1'), ('OpenCV', '4.9.0'), ('MMEngine', '0.10.3')])\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "print(mmaction.__version__)\n",
        "\n",
        "# Check MMCV installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check MMEngine installation\n",
        "from mmengine.utils.dl_utils import collect_env\n",
        "print(collect_env())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXf7oV5DWdab"
      },
      "source": [
        "## Perform inference with a MMAction2 recognizer\n",
        "MMAction2 already provides high level APIs to do inference and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "64CW6d_AaT-Q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        }
      ],
      "source": [
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \\\n",
        "      -O checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HNZB7NoSabzj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loads checkpoint by local backend from path: checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n"
          ]
        }
      ],
      "source": [
        "# MMAction2와 MMEngine 라이브러리에서 필요한 함수와 클래스를 임포트합니다.\n",
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "from mmengine import Config\n",
        "\n",
        "# 모델 구성 파일을 선택합니다. 이 구성 파일은 모델의 구조와 학습 설정을 정의합니다.\n",
        "# 여기서는 ImageNet으로 사전 훈련된 ResNet-50을 백본으로 사용하는 TSN 모델의 구성 파일입니다.\n",
        "config = 'configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py'\n",
        "\n",
        "# 선택한 구성 파일을 로드하여 Config 객체를 생성합니다.\n",
        "config = Config.fromfile(config)\n",
        "\n",
        "# 학습된 모델의 체크포인트 파일 경로를 지정합니다. \n",
        "# 이 체크포인트는 모델이 Kinetics-400 데이터셋에서 학습된 가중치를 포함합니다.\n",
        "checkpoint = 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "\n",
        "# init_recognizer 함수를 사용하여 모델을 초기화합니다. 이때, 구성 파일, 체크포인트 파일, \n",
        "# 그리고 모델을 실행할 디바이스('cuda:0'은 첫 번째 GPU를 의미합니다)를 지정합니다.\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rEMsBnpHapAn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/14 17:59:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "03/14 17:59:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n"
          ]
        }
      ],
      "source": [
        "# 필요한 함수를 임포트합니다.\n",
        "from operator import itemgetter\n",
        "\n",
        "# 인식을 수행할 비디오 파일의 경로를 지정합니다.\n",
        "video = 'demo/demo.mp4'\n",
        "# Kinetics-400 데이터셋의 라벨 매핑 파일 경로를 지정합니다.\n",
        "label = 'tools/data/kinetics/label_map_k400.txt'\n",
        "\n",
        "# 초기화한 모델을 사용하여 비디오에 대한 인식 추론을 실행합니다.\n",
        "results = inference_recognizer(model, video)\n",
        "\n",
        "# 결과에서 예측 점수를 추출하고, 리스트로 변환합니다.\n",
        "pred_scores = results.pred_score.tolist()\n",
        "# 예측 점수와 해당 인덱스를 튜플로 묶어줍니다.\n",
        "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
        "# 예측 점수를 기준으로 튜플을 내림차순으로 정렬합니다.\n",
        "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
        "# 정렬된 리스트에서 상위 5개의 라벨 인덱스와 점수를 선택합니다.\n",
        "top5_label = score_sorted[:5]\n",
        "\n",
        "# 라벨 파일을 열어 각 라인을 읽고, 줄바꿈 문자를 제거합니다.\n",
        "labels = open(label).readlines()\n",
        "labels = [x.strip() for x in labels]\n",
        "# 상위 5개의 예측 결과에 대응하는 라벨 이름과 점수를 튜플로 묶어 리스트로 만듭니다.\n",
        "results = [(labels[k[0]], k[1]) for k in top5_label]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NIyJXqfWathq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The top-5 labels with corresponding scores are:\n",
            "arm wrestling:  1.0\n",
            "rock scissors paper:  6.434453414527752e-09\n",
            "shaking hands:  2.7599860175087088e-09\n",
            "clapping:  1.345463851443185e-09\n",
            "massaging feet:  5.555100823784187e-10\n"
          ]
        }
      ],
      "source": [
        "# 상위 5개 액션 라벨과 그 점수를 출력하는 문장입니다.\n",
        "print('The top-5 labels with corresponding scores are:')\n",
        "\n",
        "# results 리스트를 반복하여 각 결과를 출력합니다.\n",
        "for result in results:\n",
        "    # result[0]은 액션 라벨의 이름을, result[1]은 해당 액션의 예측 점수를 나타냅니다.\n",
        "    # 예: 'running': 0.95\n",
        "    print(f'{result[0]}: ', result[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 코드 및 명령어 시퀀스는 MMAction2를 사용하여 사용자 지정 데이터셋에 대한 비디오 액션 인식 모델을 훈련하는 과정을 설명합니다.   \n",
        "과정은 크게 비디오 데이터의 준비, 모델의 구성 수정, 그리고 새로운 인식기의 학습으로 나눌 수 있습니다. 아래는 각 단계별 상세 설명입니다:\n",
        "\n",
        "### 비디오 데이터 준비\n",
        "- **비디오 파일 경로 지정**: `video = 'demo/demo.mp4'` 명령어는 모델이 인식을 수행할 비디오 파일의 위치를 지정합니다.\n",
        "- **라벨 매핑 파일 경로 지정**: `label = 'tools/data/kinetics/label_map_k400.txt'` 명령어는 Kinetics-400 데이터셋의 라벨을 매핑하는 파일의 위치를 지정합니다. 이 파일은 비디오에서 인식된 액션들의 이름을 포함하고 있습니다.\n",
        "\n",
        "### 모델을 이용한 비디오 인식\n",
        "- **모델을 사용하여 비디오에서 액션 인식 수행**: `results = inference_recognizer(model, video)`는 초기화된 모델을 사용하여 지정된 비디오 파일에서 액션 인식을 수행하고 결과를 반환합니다.\n",
        "- **예측 점수 추출 및 정렬**: 추출된 예측 점수를 리스트로 변환하고, 이를 내림차순으로 정렬하여 상위 5개의 결과를 선택합니다. 이 과정은 인식된 액션들 중에서 가장 확률이 높은 상위 5개를 식별합니다.\n",
        "\n",
        "### 훈련 데이터셋 다운로드 및 준비\n",
        "- **Kinetics-400 Tiny 데이터셋 다운로드**: 이 부분의 코드는 Kinetics-400 데이터셋의 작은 버전을 다운로드하고 압축을 해제합니다. 이 작은 데이터셋은 30개의 훈련 비디오와 10개의 테스트 비디오를 포함하고 있으며, 새로운 모델을 훈련하는 데 사용됩니다.\n",
        "- **데이터셋 구조 확인**: `!tree kinetics400_tiny` 명령어는 다운로드한 데이터셋의 디렉토리 구조를 확인하는 데 사용됩니다.\n",
        "- **데이터셋 주석 포맷 확인**: `!cat kinetics400_tiny/kinetics_tiny_train_video.txt` 명령어는 훈련 데이터셋의 주석 포맷을 확인하는 데 사용됩니다. 이는 모델이 학습을 수행할 때 어떤 비디오가 어떤 라벨을 가지는지 이해하는 데 필요합니다.\n",
        "\n",
        "### 사용자 지정 데이터셋에 대한 모델 훈련\n",
        "이 과정은 사용자 지정 데이터셋을 지원하기 위한 준비, 구성 수정, 그리고 새로운 인식기 훈련으로 구성됩니다. 여기서는 Kinetics-400 Tiny 데이터셋을 사용하는 예시를 통해 새 데이터셋을 다루는 방법과 모델을 훈련시키는 과정을 설명합니다.\n",
        "\n",
        "이 과정은 MMAction2를 사용하여 비디오 액션 인식 모델을 학습시키고자 할 때 필요한 기본 단계를 다룹니다. 데이터 준비부터 모델 학습까지, 각 단계는 데이터셋의 특성과 프로젝트의 요구 사항에 맞춰 조정될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuZG8kZ2fJ5d"
      },
      "source": [
        "## Train a recognizer on customized dataset\n",
        "\n",
        "To train a new recognizer, there are usually three things to do:\n",
        "1. Support a new dataset\n",
        "2. Modify the config\n",
        "3. Train a new recognizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEFyxChfgiJ"
      },
      "source": [
        "### Support a new dataset\n",
        "\n",
        "In this tutorial, we gives an example to convert the data into the format of existing datasets. Other methods and more advanced usages can be found in the [doc](/docs/tutorials/new_dataset.md)\n",
        "\n",
        "Firstly, let's download a tiny dataset obtained from [Kinetics-400](https://deepmind.com/research/open-source/open-source-datasets/kinetics/). We select 30 videos with their labels as train dataset and 10 videos with their labels as test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 코드는 사용자 지정 데이터셋으로 새로운 액션 인식 모델을 훈련시키는 과정을 설명하는 예시입니다. Kinetics-400 데이터셋의 축소된 버전을 다운로드하여 사용하여, 모델 훈련을 위한 데이터 준비 과정을 보여줍니다. 아래는 각 단계별 설명입니다:\n",
        "\n",
        "1. **새 데이터셋 지원**: 이 단계에서는 새 데이터셋을 MMAction2 또는 관련 머신러닝 프레임워크가 인식할 수 있는 형식으로 변환하는 작업을 합니다. 예시에서는 Kinetics-400의 축소 버전을 사용하지만, 실제 프로젝트에서는 자체 데이터셋을 이 형식으로 준비해야 할 수 있습니다.\n",
        "\n",
        "2. **구성 수정**: 모델의 구성 파일(config)을 수정하여 새 데이터셋에 맞게 조정합니다. 이는 데이터 경로, 모델 파라미터, 학습 루틴 등을 포함할 수 있습니다.\n",
        "\n",
        "3. **새 인식기 훈련**: 준비된 데이터셋과 수정된 구성을 바탕으로 모델 학습을 시작합니다.\n",
        "\n",
        "### 데이터셋 다운로드 및 준비 과정\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **데이터셋 다운로드 및 압축 해제**: 주어진 URL에서 Kinetics-400의 축소 버전 데이터셋을 다운로드하고 압축을 해제합니다. 이 데이터셋에는 훈련용으로 30개의 비디오와 테스트용으로 10개의 비디오가 포함되어 있습니다.\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gjsUj9JzgUlJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download and extraction complete.\n"
          ]
        }
      ],
      "source": [
        "# # download, decompress the data\n",
        "# !rm kinetics400_tiny.zip* # 기존에 다운로드된 파일이 있을 경우 삭제\n",
        "# !rm -rf kinetics400_tiny # 기존에 압축 해제된 디렉토리가 있을 경우 삭제\n",
        "# !wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip # 데이터셋 다운로드\n",
        "# !unzip kinetics400_tiny.zip > /dev/null # 압축 해제, 출력은 생략\n",
        "\n",
        "\n",
        "import requests, zipfile, io, os\n",
        "\n",
        "# 기존에 다운로드된 파일 삭제\n",
        "if os.path.exists('kinetics400_tiny.zip'):\n",
        "    os.remove('kinetics400_tiny.zip')\n",
        "\n",
        "# 기존에 압축 해제된 디렉토리 삭제\n",
        "if os.path.exists('kinetics400_tiny'):\n",
        "    os.rmdir('kinetics400_tiny')\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "url = 'https://download.openmmlab.com/mmaction/kinetics400_tiny.zip'\n",
        "response = requests.get(url)\n",
        "with open(\"kinetics400_tiny.zip\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# 압축 해제\n",
        "with zipfile.ZipFile(\"kinetics400_tiny.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "print(\"Download and extraction complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **디렉토리 구조 확인**: `tree` 명령어를 사용하여 다운로드한 데이터셋의 디렉토리 구조를 확인합니다. 이는 훈련 및 테스트 데이터가 올바르게 구성되었는지 확인하는 데 도움이 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AbZ-o7V6hNw4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kinetics400_tiny/\n",
            "    kinetics_tiny_train_video.txt\n",
            "    kinetics_tiny_val_video.txt\n",
            "    train/\n",
            "        27_CSXByd3s.mp4\n",
            "        34XczvTaRiI.mp4\n",
            "        A-wiliK50Zw.mp4\n",
            "        D32_1gwq35E.mp4\n",
            "        D92m0HsHjcQ.mp4\n",
            "        DbX8mPslRXg.mp4\n",
            "        FMlSTTpN3VY.mp4\n",
            "        h10B9SVE-nk.mp4\n",
            "        h2YqqUhnR34.mp4\n",
            "        iRuyZSKhHRg.mp4\n",
            "        IyfILH9lBRo.mp4\n",
            "        kFC3KY2bOP8.mp4\n",
            "        LvcFDgCAXQs.mp4\n",
            "        O46YA8tI530.mp4\n",
            "        oMrZaozOvdQ.mp4\n",
            "        oXy-e_P_cAI.mp4\n",
            "        P5M-hAts7MQ.mp4\n",
            "        phDqGd0NKoo.mp4\n",
            "        PnOe3GZRVX8.mp4\n",
            "        R8HXQkdgKWA.mp4\n",
            "        RqnKtCEoEcA.mp4\n",
            "        soEcZZsBmDs.mp4\n",
            "        TkkZPZHbAKA.mp4\n",
            "        T_TMNGzVrDk.mp4\n",
            "        WaS0qwP46Us.mp4\n",
            "        Wh_YPQdH1Zg.mp4\n",
            "        WWP5HZJsg-o.mp4\n",
            "        xGY2dP0YUjA.mp4\n",
            "        yLC9CtWU5ws.mp4\n",
            "        ZQV4U2KQ370.mp4\n",
            "    val/\n",
            "        0pVGiAU6XEA.mp4\n",
            "        AQrbRSnRt8M.mp4\n",
            "        b6Q_b7vgc7Q.mp4\n",
            "        ddvJ6-faICE.mp4\n",
            "        IcLztCtvhb8.mp4\n",
            "        ik4BW3-SCts.mp4\n",
            "        jqRrH30V0k4.mp4\n",
            "        SU_x2LQqSLs.mp4\n",
            "        u4Rm6srmIS8.mp4\n",
            "        y5Iu7XkTqV0.mp4\n"
          ]
        }
      ],
      "source": [
        "# # Check the directory structure of the tiny data\n",
        "\n",
        "# # Install tree first\n",
        "# !apt-get -q install tree # tree 명령어 설치\n",
        "# !tree kinetics400_tiny # 데이터셋 디렉토리 구조 출력\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "def list_files(startpath):\n",
        "    for root, dirs, files in os.walk(startpath):\n",
        "        level = root.replace(startpath, '').count(os.sep)\n",
        "        indent = ' ' * 4 * (level)\n",
        "        print(f'{indent}{os.path.basename(root)}/')\n",
        "        subindent = ' ' * 4 * (level + 1)\n",
        "        for f in files:\n",
        "            print(f'{subindent}{f}')\n",
        "\n",
        "# 경로를 원하는 데이터셋 디렉토리로 변경하세요.\n",
        "list_files('kinetics400_tiny')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fTdi6dI0hY3g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D32_1gwq35E.mp4 0\n",
            "iRuyZSKhHRg.mp4 1\n",
            "oXy-e_P_cAI.mp4 0\n",
            "34XczvTaRiI.mp4 1\n",
            "h2YqqUhnR34.mp4 0\n",
            "O46YA8tI530.mp4 0\n",
            "kFC3KY2bOP8.mp4 1\n",
            "WWP5HZJsg-o.mp4 1\n",
            "phDqGd0NKoo.mp4 1\n",
            "yLC9CtWU5ws.mp4 0\n",
            "27_CSXByd3s.mp4 1\n",
            "IyfILH9lBRo.mp4 1\n",
            "T_TMNGzVrDk.mp4 1\n",
            "TkkZPZHbAKA.mp4 0\n",
            "PnOe3GZRVX8.mp4 1\n",
            "soEcZZsBmDs.mp4 1\n",
            "FMlSTTpN3VY.mp4 1\n",
            "WaS0qwP46Us.mp4 0\n",
            "A-wiliK50Zw.mp4 1\n",
            "oMrZaozOvdQ.mp4 1\n",
            "ZQV4U2KQ370.mp4 0\n",
            "DbX8mPslRXg.mp4 1\n",
            "h10B9SVE-nk.mp4 1\n",
            "P5M-hAts7MQ.mp4 0\n",
            "R8HXQkdgKWA.mp4 0\n",
            "D92m0HsHjcQ.mp4 0\n",
            "RqnKtCEoEcA.mp4 0\n",
            "LvcFDgCAXQs.mp4 0\n",
            "xGY2dP0YUjA.mp4 0\n",
            "Wh_YPQdH1Zg.mp4 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # After downloading the data, we need to check the annotation format\n",
        "# !cat kinetics400_tiny/kinetics_tiny_train_video.txt # 주석 파일 내용 출력\n",
        "\n",
        "\n",
        "# 파일 경로를 정확하게 지정해주세요.\n",
        "file_path = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "    print(content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bq0mxmEi29H"
      },
      "source": [
        "According to the format defined in [`VideoDataset`](./datasets/video_dataset.py), each line indicates a sample video with the filepath and label, which are split with a whitespace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DGJA9jQar"
      },
      "source": [
        "### Modify the config\n",
        "\n",
        "In the next step, we need to modify the config for the training.\n",
        "To accelerate the process, we finetune a recognizer using a pre-trained recognizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LjCcmCKOjktc"
      },
      "outputs": [],
      "source": [
        "# MMAction2 설정 파일을 로드합니다. 이 설정 파일은 TSN(Temporal Segment Networks) 모델이 \n",
        "# ImageNet으로 사전 훈련된 ResNet-50을 기반으로 하며, Kinetics-400 데이터셋에 대해 \n",
        "# 훈련될 때 사용되는 구성을 정의합니다.\n",
        "# 여기서:\n",
        "# - 'tsn_imagenet-pretrained-r50'는 ImageNet으로 사전 훈련된 ResNet-50을 사용한다는 것을 의미합니다.\n",
        "# - '8xb32'는 8개의 GPUs를 사용하며, 각 GPU 당 배치 크기가 32임을 나타냅니다.\n",
        "# - '1x1x3-100e'는 학습 스케쥴을 나타내며, 보통 이는 학습률 변경 지점과 총 에폭 수(여기서는 100 에폭)를 의미합니다.\n",
        "# - 'kinetics400-rgb'는 Kinetics-400 데이터셋의 RGB 비디오 프레임을 사용한다는 것을 의미합니다.\n",
        "cfg = Config.fromfile('./configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc8YhFFGjp3e"
      },
      "source": [
        "Given a config that trains a TSN model on kinetics400-full dataset, we need to modify some values to use it for training TSN on Kinetics400-tiny dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tlhu9byjjt-K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
            "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "auto_scale_lr = dict(base_batch_size=256, enable=False)\n",
            "data_root = 'kinetics400_tiny/train/'\n",
            "data_root_val = 'kinetics400_tiny/val/'\n",
            "dataset_type = 'VideoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=3, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "file_client_args = dict(io_backend='disk')\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        depth=50,\n",
            "        norm_eval=False,\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        type='ResNet'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        consensus=dict(dim=1, type='AvgConsensus'),\n",
            "        dropout_ratio=0.4,\n",
            "        in_channels=2048,\n",
            "        init_std=0.01,\n",
            "        num_classes=2,\n",
            "        spatial_type='avg',\n",
            "        type='TSNHead'),\n",
            "    data_preprocessor=dict(\n",
            "        format_shape='NCHW',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    test_cfg=None,\n",
            "    train_cfg=None,\n",
            "    type='Recognizer2D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=40, norm_type=2),\n",
            "    optimizer=dict(\n",
            "        lr=7.8125e-05, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=100,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            40,\n",
            "            80,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='TenCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='TenCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_epochs=10, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/train/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1, frame_interval=1, num_clips=3,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(\n",
            "                input_size=224,\n",
            "                max_wh_scale_gap=1,\n",
            "                random_crop=False,\n",
            "                scales=(\n",
            "                    1,\n",
            "                    0.875,\n",
            "                    0.75,\n",
            "                    0.66,\n",
            "                ),\n",
            "                type='MultiScaleCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='VideoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=1, frame_interval=1, num_clips=3, type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(\n",
            "        input_size=224,\n",
            "        max_wh_scale_gap=1,\n",
            "        random_crop=False,\n",
            "        scales=(\n",
            "            1,\n",
            "            0.875,\n",
            "            0.75,\n",
            "            0.66,\n",
            "        ),\n",
            "        type='MultiScaleCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=3,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=3,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './tutorial_exps'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmengine.runner import set_random_seed\n",
        "\n",
        "# 학습 및 검증 데이터셋의 루트 경로를 설정합니다.\n",
        "cfg.data_root = 'kinetics400_tiny/train/'\n",
        "cfg.data_root_val = 'kinetics400_tiny/val/'\n",
        "\n",
        "# 학습 및 검증 데이터셋의 어노테이션 파일 경로를 설정합니다.\n",
        "cfg.ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "\n",
        "# 테스트 데이터셋의 어노테이션 파일 및 비디오 파일 경로를 설정합니다.\n",
        "cfg.test_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.test_dataloader.dataset.data_prefix.video = 'kinetics400_tiny/val/'\n",
        "\n",
        "# 학습 데이터셋의 어노테이션 파일 및 비디오 파일 경로를 설정합니다.\n",
        "cfg.train_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.train_dataloader.dataset.data_prefix.video = 'kinetics400_tiny/train/'\n",
        "\n",
        "# 검증 데이터셋의 어노테이션 파일 및 비디오 파일 경로를 설정합니다.\n",
        "cfg.val_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.val_dataloader.dataset.data_prefix.video  = 'kinetics400_tiny/val/'\n",
        "\n",
        "# 모델의 분류기 머리 부분에서 클래스의 수를 수정합니다. 여기서는 2로 설정합니다.\n",
        "cfg.model.cls_head.num_classes = 2\n",
        "\n",
        "# 사전 훈련된 TSN 모델을 사용합니다.\n",
        "cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "\n",
        "# 파일과 로그를 저장할 작업 디렉토리를 설정합니다.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# 원래 학습률(LR)은 8-GPU 학습에 맞춰 설정되어 있습니다.\n",
        "# 하나의 GPU만 사용하기 때문에 이를 8로 나눕니다.\n",
        "cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 16\n",
        "cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 16\n",
        "cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8 / 16\n",
        "\n",
        "# 최대 에폭 수를 10으로 설정합니다.\n",
        "cfg.train_cfg.max_epochs = 10\n",
        "\n",
        "# 데이터 로더의 작업자 수를 설정합니다.\n",
        "cfg.train_dataloader.num_workers = 2\n",
        "cfg.val_dataloader.num_workers = 2\n",
        "cfg.test_dataloader.num_workers = 2\n",
        "\n",
        "# 훈련을 위해 최종 사용된 설정을 로거로 초기화하고 확인합니다.\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES-qnZ3k38Z"
      },
      "source": [
        "### Train a new recognizer\n",
        "\n",
        "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dDBWkdDRk6oz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/14 14:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: win32\n",
            "    Python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1383582061\n",
            "    GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU\n",
            "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\n",
            "    NVCC: Cuda compilation tools, release 12.3, V12.3.103\n",
            "    MSVC: n/a, reason: fileno\n",
            "    PyTorch: 2.2.1\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - C++ Version: 201703\n",
            "  - MSVC 192930151\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)\n",
            "  - OpenMP 2019\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.8.1  (built against CUDA 12.0)\n",
            "  - Magma 2.5.4\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
            "\n",
            "    TorchVision: 0.17.1\n",
            "    OpenCV: 4.9.0\n",
            "    MMEngine: 0.10.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1383582061\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "03/14 14:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
            "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "auto_scale_lr = dict(base_batch_size=256, enable=False)\n",
            "data_root = 'kinetics400_tiny/train/'\n",
            "data_root_val = 'kinetics400_tiny/val/'\n",
            "dataset_type = 'VideoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=3, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "file_client_args = dict(io_backend='disk')\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        depth=50,\n",
            "        norm_eval=False,\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        type='ResNet'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        consensus=dict(dim=1, type='AvgConsensus'),\n",
            "        dropout_ratio=0.4,\n",
            "        in_channels=2048,\n",
            "        init_std=0.01,\n",
            "        num_classes=2,\n",
            "        spatial_type='avg',\n",
            "        type='TSNHead'),\n",
            "    data_preprocessor=dict(\n",
            "        format_shape='NCHW',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    test_cfg=None,\n",
            "    train_cfg=None,\n",
            "    type='Recognizer2D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=40, norm_type=2),\n",
            "    optimizer=dict(\n",
            "        lr=7.8125e-05, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=100,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            40,\n",
            "            80,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='TenCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='TenCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_epochs=10, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/train/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1, frame_interval=1, num_clips=3,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(\n",
            "                input_size=224,\n",
            "                max_wh_scale_gap=1,\n",
            "                random_crop=False,\n",
            "                scales=(\n",
            "                    1,\n",
            "                    0.875,\n",
            "                    0.75,\n",
            "                    0.66,\n",
            "                ),\n",
            "                type='MultiScaleCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='VideoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=1, frame_interval=1, num_clips=3, type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(\n",
            "        input_size=224,\n",
            "        max_wh_scale_gap=1,\n",
            "        random_crop=False,\n",
            "        scales=(\n",
            "            1,\n",
            "            0.875,\n",
            "            0.75,\n",
            "            0.66,\n",
            "        ),\n",
            "        type='MultiScaleCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=3,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=3,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './tutorial_exps'\n",
            "\n",
            "03/14 14:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "03/14 14:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "Loads checkpoint by http backend from path: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\chanj/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/14 14:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n",
            "Loads checkpoint by local backend from path: ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
            "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "03/14 14:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "03/14 14:49:18 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "03/14 14:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to c:\\Users\\chanj\\workspace\\Anaconda for AI\\mmaction2\\tutorial_exps.\n",
            "03/14 14:49:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][15/15]  lr: 7.8125e-05  eta: 0:01:08  time: 0.5097  data_time: 0.3216  memory: 2918  grad_norm: 13.3939  loss: 0.7642  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7642\n",
            "03/14 14:49:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][5/5]    acc/top1: 0.3000  acc/top5: 1.0000  acc/mean1: 0.3000  data_time: 0.8014  time: 0.8557\n",
            "03/14 14:49:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.3000 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
            "03/14 14:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][15/15]  lr: 7.8125e-05  eta: 0:00:39  time: 0.1420  data_time: 0.0095  memory: 939  grad_norm: 12.9979  loss: 0.7537  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7537\n",
            "03/14 14:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][5/5]    acc/top1: 0.5000  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0808  time: 0.1038\n",
            "03/14 14:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\chanj\\workspace\\Anaconda for AI\\mmaction2\\tutorial_exps\\best_acc_top1_epoch_1.pth is removed\n",
            "03/14 14:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5000 acc/top1 at 2 epoch is saved to best_acc_top1_epoch_2.pth.\n",
            "03/14 14:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][15/15]  lr: 7.8125e-05  eta: 0:00:27  time: 0.1406  data_time: 0.0074  memory: 939  grad_norm: 12.3561  loss: 0.7176  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7176\n",
            "03/14 14:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "03/14 14:49:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][5/5]    acc/top1: 0.6000  acc/top5: 1.0000  acc/mean1: 0.6000  data_time: 0.1053  time: 0.1190\n",
            "03/14 14:49:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\chanj\\workspace\\Anaconda for AI\\mmaction2\\tutorial_exps\\best_acc_top1_epoch_2.pth is removed\n",
            "03/14 14:49:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6000 acc/top1 at 3 epoch is saved to best_acc_top1_epoch_3.pth.\n",
            "03/14 14:49:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][15/15]  lr: 7.8125e-05  eta: 0:00:21  time: 0.1482  data_time: 0.0111  memory: 939  grad_norm: 12.7791  loss: 0.7148  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7148\n",
            "03/14 14:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][5/5]    acc/top1: 0.6000  acc/top5: 1.0000  acc/mean1: 0.6000  data_time: 0.1034  time: 0.1174\n",
            "03/14 14:49:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][15/15]  lr: 7.8125e-05  eta: 0:00:16  time: 0.1419  data_time: 0.0078  memory: 939  grad_norm: 12.6587  loss: 0.7258  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7258\n",
            "03/14 14:49:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.1048  time: 0.1189\n",
            "03/14 14:49:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\chanj\\workspace\\Anaconda for AI\\mmaction2\\tutorial_exps\\best_acc_top1_epoch_3.pth is removed\n",
            "03/14 14:49:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7000 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
            "03/14 14:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][15/15]  lr: 7.8125e-05  eta: 0:00:12  time: 0.1426  data_time: 0.0087  memory: 939  grad_norm: 13.0150  loss: 0.6984  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6984\n",
            "03/14 14:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
            "03/14 14:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.1018  time: 0.1158\n",
            "03/14 14:49:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][15/15]  lr: 7.8125e-05  eta: 0:00:08  time: 0.1418  data_time: 0.0100  memory: 939  grad_norm: 12.7434  loss: 0.6645  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6645\n",
            "03/14 14:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][5/5]    acc/top1: 0.8000  acc/top5: 1.0000  acc/mean1: 0.8000  data_time: 0.1019  time: 0.1163\n",
            "03/14 14:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\chanj\\workspace\\Anaconda for AI\\mmaction2\\tutorial_exps\\best_acc_top1_epoch_5.pth is removed\n",
            "03/14 14:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.8000 acc/top1 at 7 epoch is saved to best_acc_top1_epoch_7.pth.\n",
            "03/14 14:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][15/15]  lr: 7.8125e-05  eta: 0:00:05  time: 0.1412  data_time: 0.0069  memory: 939  grad_norm: 12.6159  loss: 0.6769  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6769\n",
            "03/14 14:49:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][5/5]    acc/top1: 0.9000  acc/top5: 1.0000  acc/mean1: 0.9000  data_time: 0.1013  time: 0.1159\n",
            "03/14 14:49:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\chanj\\workspace\\Anaconda for AI\\mmaction2\\tutorial_exps\\best_acc_top1_epoch_7.pth is removed\n",
            "03/14 14:49:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.9000 acc/top1 at 8 epoch is saved to best_acc_top1_epoch_8.pth.\n",
            "03/14 14:50:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:50:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][15/15]  lr: 7.8125e-05  eta: 0:00:02  time: 0.1417  data_time: 0.0080  memory: 939  grad_norm: 12.9484  loss: 0.6752  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6752\n",
            "03/14 14:50:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
            "03/14 14:50:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][5/5]    acc/top1: 0.9000  acc/top5: 1.0000  acc/mean1: 0.9000  data_time: 0.1002  time: 0.1141\n",
            "03/14 14:50:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240314_144903\n",
            "03/14 14:50:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][15/15]  lr: 7.8125e-05  eta: 0:00:00  time: 0.1400  data_time: 0.0090  memory: 939  grad_norm: 12.6186  loss: 0.6625  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6625\n",
            "03/14 14:50:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
            "03/14 14:50:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][5/5]    acc/top1: 0.9000  acc/top5: 1.0000  acc/mean1: 0.9000  data_time: 0.1041  time: 0.1173\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Recognizer2D(\n",
              "  (data_preprocessor): ActionDataPreprocessor()\n",
              "  (backbone): ResNet(\n",
              "    (conv1): ConvModule(\n",
              "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activate): ReLU(inplace=True)\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1.0}]\n",
              "  (cls_head): TSNHead(\n",
              "    (loss_cls): CrossEntropyLoss()\n",
              "    (consensus): AvgConsensus()\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "    (fc_cls): Linear(in_features=2048, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import mmengine\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "# 작업 디렉토리를 생성합니다. 모델 학습 중 생성되는 파일과 로그를 저장하기 위한 디렉토리입니다.\n",
        "mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "\n",
        "# 설정 파일을 기반으로 학습 실행자(Runner)를 구축합니다. Runner는 학습 과정을 관리합니다.\n",
        "runner = Runner.from_cfg(cfg)\n",
        "\n",
        "# 학습을 시작합니다. 이 과정은 데이터셋을 사용하여 모델을 학습하고, 설정된 에폭 수만큼 반복합니다.\n",
        "runner.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSd7oTLlxIf"
      },
      "source": [
        "### Understand the log\n",
        "From the log, we can have a basic understanding the training process and know how well the recognizer is trained.\n",
        "\n",
        "Firstly, the ResNet-50 backbone pre-trained on ImageNet is loaded, this is a common practice since training from scratch is more cost. The log shows that all the weights of the ResNet-50 backbone are loaded except the `fc.bias` and `fc.weight`.\n",
        "\n",
        "Second, since the dataset we are using is small, we loaded a TSN model and finetune it for action recognition.\n",
        "The original TSN is trained on original Kinetics-400 dataset which contains 400 classes but Kinetics-400 Tiny dataset only have 2 classes. Therefore, the last FC layer of the pre-trained TSN for classification has different weight shape and is not used.\n",
        "\n",
        "Third, after training, the recognizer is evaluated by the default evaluation. The results show that the recognizer achieves 100% top1 accuracy and 100% top5 accuracy on the val dataset,\n",
        "\n",
        "Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 로그 이해하기\n",
        "학습 과정 중 생성된 로그는 모델 학습의 진행 상황과 성능을 이해하는 데 도움을 줍니다.\n",
        "\n",
        "- **첫째**, ImageNet으로 사전 훈련된 ResNet-50 백본이 로드됩니다. 이는 처음부터 훈련하는 것보다 비용이 적게 드는 일반적인 관행입니다. 로그에서는 ResNet-50 백본의 모든 가중치가 로드되었음을 보여주지만, `fc.bias`와 `fc.weight`는 제외됩니다.\n",
        "\n",
        "- **둘째**, 사용 중인 데이터셋이 작기 때문에, TSN 모델을 로드하고 액션 인식을 위해 미세 조정(finetune)합니다. 원래의 TSN은 400개 클래스를 포함하는 원본 Kinetics-400 데이터셋에서 훈련되었지만, Kinetics-400 Tiny 데이터셋은 오직 2개의 클래스만을 가지고 있습니다. 따라서, 사전 훈련된 TSN의 분류를 위한 마지막 FC 계층은 가중치 형태가 다르므로 사용되지 않습니다.\n",
        "\n",
        "- **셋째**, 훈련 후, 모델은 기본 평가로 평가됩니다. 결과는 평가 데이터셋에서 100%의 top1 정확도와 100%의 top5 정확도를 달성했다고 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVoSfZVmogw"
      },
      "source": [
        "## Test the trained recognizer\n",
        "\n",
        "After finetuning the recognizer, let's check the prediction results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 훈련된 인식기 테스트하기\n",
        "모델을 미세 조정한 후, 예측 결과를 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eyY3hCMwyTct"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/14 14:54:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [10/10]    acc/top1: 0.9000  acc/top5: 1.0000  acc/mean1: 0.9000  data_time: 0.4100  time: 1.1401\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'acc/top1': 0.9, 'acc/top5': 1.0, 'acc/mean1': 0.9}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 훈련된 모델을 사용하여 테스트 데이터셋에 대한 예측을 수행합니다.\n",
        "runner.test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 단계는 모델이 얼마나 잘 학습되었는지, 즉 새로운 데이터에 대한 모델의 일반화 능력을 평가하는 과정입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf2f7bGmy6-P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "189c342a4747645665e89db23000ac4d4edb7a87c4cd0b2f881610f468fb778d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
